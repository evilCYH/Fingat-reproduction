{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bed0ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:35:32.960137Z",
     "iopub.status.busy": "2023-11-28T09:35:32.959772Z",
     "iopub.status.idle": "2023-11-28T09:35:35.367781Z",
     "shell.execute_reply": "2023-11-28T09:35:35.367150Z",
     "shell.execute_reply.started": "2023-11-28T09:35:32.960094Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, SAGPooling,global_mean_pool , global_max_pool \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749bdbc4-e851-40f2-9800-32104754a1ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## fingat源码的关于编码的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7d270cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:35:37.300001Z",
     "iopub.status.busy": "2023-11-28T09:35:37.299663Z",
     "iopub.status.idle": "2023-11-28T09:35:37.306192Z",
     "shell.execute_reply": "2023-11-28T09:35:37.305747Z",
     "shell.execute_reply.started": "2023-11-28T09:35:37.299976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self,time_step,dim):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention_matrix = nn.Linear(time_step, time_step)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs_t = torch.transpose(inputs,2,1) # (batch_size, input_dim, time_step)\n",
    "        attention_weight = self.attention_matrix(inputs_t)\n",
    "        attention_probs = F.softmax(attention_weight,dim=-1)\n",
    "        attention_probs = torch.transpose(attention_probs,2,1)\n",
    "        attention_vec = torch.mul(attention_probs, inputs)\n",
    "        attention_vec = torch.sum(attention_vec,dim=1)\n",
    "        return attention_vec, attention_probs\n",
    "\n",
    "class SequenceEncoder(nn.Module):\n",
    "    def __init__(self,input_dim,time_step,hidden_dim):\n",
    "        super(SequenceEncoder, self).__init__()\n",
    "        self.encoder = nn.GRU(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,batch_first=True)\n",
    "        self.attention_block = AttentionBlock(time_step,hidden_dim) \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dim = hidden_dim\n",
    "    \n",
    "    def forward(self,seq):\n",
    "        '''\n",
    "        inp : torch.tensor (batch,time_step,input_dim)\n",
    "        '''\n",
    "        seq_vector,_ = self.encoder(seq)\n",
    "        seq_vector = self.dropout(seq_vector)\n",
    "        attention_vec, attention_probs = self.attention_block(seq_vector)\n",
    "        attention_vec = attention_vec.view(-1,1,self.dim) # prepare for concat\n",
    "        return attention_vec, attention_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603a489-7b12-47da-a057-ba6fb13d903d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:32:24.953710Z",
     "iopub.status.busy": "2023-11-26T07:32:24.953283Z",
     "iopub.status.idle": "2023-11-26T07:32:24.958082Z",
     "shell.execute_reply": "2023-11-26T07:32:24.956965Z",
     "shell.execute_reply.started": "2023-11-26T07:32:24.953670Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c451532d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:35:54.783106Z",
     "iopub.status.busy": "2023-11-28T09:35:54.782851Z",
     "iopub.status.idle": "2023-11-28T09:35:57.436676Z",
     "shell.execute_reply": "2023-11-28T09:35:57.435901Z",
     "shell.execute_reply.started": "2023-11-28T09:35:54.783085Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./datasets3/sp500_data.pkl', \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ae43f7b-cde2-47ac-b99f-39d8f0367bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:00.982884Z",
     "iopub.status.busy": "2023-11-28T09:36:00.982642Z",
     "iopub.status.idle": "2023-11-28T09:36:01.099139Z",
     "shell.execute_reply": "2023-11-28T09:36:01.098620Z",
     "shell.execute_reply.started": "2023-11-28T09:36:00.982861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a61512cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:01.757206Z",
     "iopub.status.busy": "2023-11-28T09:36:01.756992Z",
     "iopub.status.idle": "2023-11-28T09:36:01.765922Z",
     "shell.execute_reply": "2023-11-28T09:36:01.765289Z",
     "shell.execute_reply.started": "2023-11-28T09:36:01.757178Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577, 475, 7, 29)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = data['train']['x1'][:,:,:,1:]\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fca6f6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:03.149904Z",
     "iopub.status.busy": "2023-11-28T09:36:03.149526Z",
     "iopub.status.idle": "2023-11-28T09:36:03.156001Z",
     "shell.execute_reply": "2023-11-28T09:36:03.155498Z",
     "shell.execute_reply.started": "2023-11-28T09:36:03.149864Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 475, 7, 29)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = data['test']['x1'][:,:,:,1:]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8744be9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:04.566394Z",
     "iopub.status.busy": "2023-11-28T09:36:04.566024Z",
     "iopub.status.idle": "2023-11-28T09:36:04.571996Z",
     "shell.execute_reply": "2023-11-28T09:36:04.571513Z",
     "shell.execute_reply.started": "2023-11-28T09:36:04.566356Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1577, 475)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = data['train']['y_return ratio']\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3cba196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:05.327654Z",
     "iopub.status.busy": "2023-11-28T09:36:05.327288Z",
     "iopub.status.idle": "2023-11-28T09:36:05.333924Z",
     "shell.execute_reply": "2023-11-28T09:36:05.333148Z",
     "shell.execute_reply.started": "2023-11-28T09:36:05.327605Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 475)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = data['test']['y_return ratio']\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287c60f-46ab-4685-8226-aeb65bc8dcc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:32:49.001429Z",
     "iopub.status.busy": "2023-11-26T07:32:49.000994Z",
     "iopub.status.idle": "2023-11-26T07:32:49.005612Z",
     "shell.execute_reply": "2023-11-26T07:32:49.004810Z",
     "shell.execute_reply.started": "2023-11-26T07:32:49.001389Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 设立pytorch的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0de5ad44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:07.629675Z",
     "iopub.status.busy": "2023-11-28T09:36:07.629303Z",
     "iopub.status.idle": "2023-11-28T09:36:07.637508Z",
     "shell.execute_reply": "2023-11-28T09:36:07.636452Z",
     "shell.execute_reply.started": "2023-11-28T09:36:07.629635Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def create_dataloader(x, y, batch_size):\n",
    "    dataset = StockDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e48c4d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:14.493001Z",
     "iopub.status.busy": "2023-11-28T09:36:14.492703Z",
     "iopub.status.idle": "2023-11-28T09:36:14.497534Z",
     "shell.execute_reply": "2023-11-28T09:36:14.496988Z",
     "shell.execute_reply.started": "2023-11-28T09:36:14.492974Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(train_x, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bd7e2a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:18.150001Z",
     "iopub.status.busy": "2023-11-28T09:36:18.149745Z",
     "iopub.status.idle": "2023-11-28T09:36:18.287203Z",
     "shell.execute_reply": "2023-11-28T09:36:18.286692Z",
     "shell.execute_reply.started": "2023-11-28T09:36:18.149978Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "1\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "2\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "3\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "4\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "5\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "6\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "7\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "8\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "9\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "10\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "11\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "12\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "13\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "14\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "15\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "16\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "17\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "18\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "19\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "20\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "21\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "22\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "23\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "24\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "25\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "26\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "27\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "28\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "29\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "30\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "31\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "32\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "33\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "34\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "35\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "36\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "37\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "38\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "39\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "40\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "41\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "42\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "43\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "44\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "45\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "46\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "47\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "48\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "49\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "50\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "51\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "52\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "53\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "54\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "55\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "56\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "57\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "58\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "59\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "60\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "61\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "62\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "63\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "64\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "65\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "66\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "67\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "68\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "69\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "70\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "71\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "72\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "73\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "74\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "75\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "76\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "77\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "78\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "79\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "80\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "81\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "82\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "83\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "84\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "85\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "86\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "87\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "88\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "89\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "90\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "91\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "92\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "93\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "94\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "95\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "96\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "97\n",
      "torch.Size([16, 475, 7, 29])\n",
      "torch.Size([16, 475])\n",
      "=========================\n",
      "98\n",
      "torch.Size([9, 475, 7, 29])\n",
      "torch.Size([9, 475])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (seq, target) in enumerate(dataloader):\n",
    "    print(batch_idx)\n",
    "    print(seq.shape)\n",
    "    print(target.shape)\n",
    "    print(\"=========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e9054-8289-4ffb-ab42-bbaed1735381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:33:44.456985Z",
     "iopub.status.busy": "2023-11-26T07:33:44.456659Z",
     "iopub.status.idle": "2023-11-26T07:33:44.459472Z",
     "shell.execute_reply": "2023-11-26T07:33:44.458982Z",
     "shell.execute_reply.started": "2023-11-26T07:33:44.456966Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 建立模型，设置优化器、损失，进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2815be93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:36:49.654271Z",
     "iopub.status.busy": "2023-11-28T09:36:49.654025Z",
     "iopub.status.idle": "2023-11-28T09:36:49.658712Z",
     "shell.execute_reply": "2023-11-28T09:36:49.658195Z",
     "shell.execute_reply.started": "2023-11-28T09:36:49.654250Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 建立\n",
    "sequence_encoder = SequenceEncoder(input_dim=29, time_step=7, hidden_dim=64)\n",
    "\n",
    "# 定义损失和优化\n",
    "criterion = nn.MSELoss()  # 因为是回归问题，所以我们使用均方误差损失\n",
    "optimizer = Adam(sequence_encoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f801e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:37:00.722823Z",
     "iopub.status.busy": "2023-11-28T09:37:00.722399Z",
     "iopub.status.idle": "2023-11-28T09:37:22.638033Z",
     "shell.execute_reply": "2023-11-28T09:37:22.637461Z",
     "shell.execute_reply.started": "2023-11-28T09:37:00.722780Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([7600, 1])) that is different to the input size (torch.Size([7600, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss 0.01323576271533966\n",
      "Epoch 0, Batch 20, Loss 0.005960122682154179\n",
      "Epoch 0, Batch 40, Loss 0.0030632023699581623\n",
      "Epoch 0, Batch 60, Loss 0.0022106030955910683\n",
      "Epoch 0, Batch 80, Loss 0.0010974928736686707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([4275, 1])) that is different to the input size (torch.Size([4275, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save!\n",
      "Epoch 1, Batch 0, Loss 0.0010343975154682994\n",
      "Epoch 1, Batch 20, Loss 0.0005980537971481681\n",
      "Epoch 1, Batch 40, Loss 0.0004282526788301766\n",
      "Epoch 1, Batch 60, Loss 0.0004119219083804637\n",
      "Epoch 1, Batch 80, Loss 0.00034123024670407176\n",
      "save!\n",
      "Epoch 2, Batch 0, Loss 0.0002599103609099984\n",
      "Epoch 2, Batch 20, Loss 0.0003521883918438107\n",
      "Epoch 2, Batch 40, Loss 0.00031057122396305203\n",
      "Epoch 2, Batch 60, Loss 0.0002388919674558565\n",
      "Epoch 2, Batch 80, Loss 0.0003080145106650889\n",
      "save!\n",
      "Epoch 3, Batch 0, Loss 0.0003723150584846735\n",
      "Epoch 3, Batch 20, Loss 0.0002213188272435218\n",
      "Epoch 3, Batch 40, Loss 0.0002564689493738115\n",
      "Epoch 3, Batch 60, Loss 0.0011172927916049957\n",
      "Epoch 3, Batch 80, Loss 0.00043539382750168443\n",
      "Epoch 4, Batch 0, Loss 0.0005616576527245343\n",
      "Epoch 4, Batch 20, Loss 0.0003458669234532863\n",
      "Epoch 4, Batch 40, Loss 0.00039282639045268297\n",
      "Epoch 4, Batch 60, Loss 0.0002571314398664981\n",
      "Epoch 4, Batch 80, Loss 0.0003368014586158097\n",
      "save!\n",
      "Epoch 5, Batch 0, Loss 0.00024942727759480476\n",
      "Epoch 5, Batch 20, Loss 0.0003186306857969612\n",
      "Epoch 5, Batch 40, Loss 0.0002767640398815274\n",
      "Epoch 5, Batch 60, Loss 0.0006926016649231315\n",
      "Epoch 5, Batch 80, Loss 0.0002363721578149125\n",
      "Epoch 6, Batch 0, Loss 0.00025325885508209467\n",
      "Epoch 6, Batch 20, Loss 0.000798035180196166\n",
      "Epoch 6, Batch 40, Loss 0.00029353072750382125\n",
      "Epoch 6, Batch 60, Loss 0.00030860822880640626\n",
      "Epoch 6, Batch 80, Loss 0.00043695620843209326\n",
      "Epoch 7, Batch 0, Loss 0.0008892695186659694\n",
      "Epoch 7, Batch 20, Loss 0.00036484721931628883\n",
      "Epoch 7, Batch 40, Loss 0.00031016458524391055\n",
      "Epoch 7, Batch 60, Loss 0.00032371998531743884\n",
      "Epoch 7, Batch 80, Loss 0.0002397168573224917\n",
      "Epoch 8, Batch 0, Loss 0.0002805306576192379\n",
      "Epoch 8, Batch 20, Loss 0.00033144064946100116\n",
      "Epoch 8, Batch 40, Loss 0.0002863746485672891\n",
      "Epoch 8, Batch 60, Loss 0.00023917351791169494\n",
      "Epoch 8, Batch 80, Loss 0.00039161345921456814\n",
      "Epoch 9, Batch 0, Loss 0.00028279205434955657\n",
      "Epoch 9, Batch 20, Loss 0.00024274401948787272\n",
      "Epoch 9, Batch 40, Loss 0.00039237868622876704\n",
      "Epoch 9, Batch 60, Loss 0.00041095277993008494\n",
      "Epoch 9, Batch 80, Loss 0.00031923034111969173\n",
      "Epoch 10, Batch 0, Loss 0.00047388370148837566\n",
      "Epoch 10, Batch 20, Loss 0.00031603837851434946\n",
      "Epoch 10, Batch 40, Loss 0.0003841528668999672\n",
      "Epoch 10, Batch 60, Loss 0.0010206819279119372\n",
      "Epoch 10, Batch 80, Loss 0.00040290673496201634\n",
      "Epoch 11, Batch 0, Loss 0.0002290614793309942\n",
      "Epoch 11, Batch 20, Loss 0.00041845475789159536\n",
      "Epoch 11, Batch 40, Loss 0.00043628146522678435\n",
      "Epoch 11, Batch 60, Loss 0.00045412362669594586\n",
      "Epoch 11, Batch 80, Loss 0.0003496397694107145\n",
      "Epoch 12, Batch 0, Loss 0.0002686736988835037\n",
      "Epoch 12, Batch 20, Loss 0.00029422531952150166\n",
      "Epoch 12, Batch 40, Loss 0.00025027149240486324\n",
      "Epoch 12, Batch 60, Loss 0.0002981106808874756\n",
      "Epoch 12, Batch 80, Loss 0.0005716448649764061\n",
      "Epoch 13, Batch 0, Loss 0.0007504688110202551\n",
      "Epoch 13, Batch 20, Loss 0.0002448770101182163\n",
      "Epoch 13, Batch 40, Loss 0.00032701229793019593\n",
      "Epoch 13, Batch 60, Loss 0.0005189726362004876\n",
      "Epoch 13, Batch 80, Loss 0.00021857199317310005\n",
      "Epoch 14, Batch 0, Loss 0.00028829919756390154\n",
      "Epoch 14, Batch 20, Loss 0.00045469790347851813\n",
      "Epoch 14, Batch 40, Loss 0.00039135097176767886\n",
      "Epoch 14, Batch 60, Loss 0.0015217793406918645\n",
      "Epoch 14, Batch 80, Loss 0.000316912803100422\n",
      "Epoch 15, Batch 0, Loss 0.0014462950639426708\n",
      "Epoch 15, Batch 20, Loss 0.001126422081142664\n",
      "Epoch 15, Batch 40, Loss 0.0003472967364359647\n",
      "Epoch 15, Batch 60, Loss 0.0003021098964381963\n",
      "Epoch 15, Batch 80, Loss 0.00023212154337670654\n",
      "Epoch 16, Batch 0, Loss 0.00029319949680939317\n",
      "Epoch 16, Batch 20, Loss 0.000378384196665138\n",
      "Epoch 16, Batch 40, Loss 0.0016041556373238564\n",
      "Epoch 16, Batch 60, Loss 0.0003414978855289519\n",
      "Epoch 16, Batch 80, Loss 0.0002535540843382478\n",
      "Epoch 17, Batch 0, Loss 0.0010432221461087465\n",
      "Epoch 17, Batch 20, Loss 0.00029567538877017796\n",
      "Epoch 17, Batch 40, Loss 0.0003403350419830531\n",
      "Epoch 17, Batch 60, Loss 0.000278770225122571\n",
      "Epoch 17, Batch 80, Loss 0.0003496842982713133\n",
      "Epoch 18, Batch 0, Loss 0.0012265043333172798\n",
      "Epoch 18, Batch 20, Loss 0.00038948748260736465\n",
      "Epoch 18, Batch 40, Loss 0.00030759471701458097\n",
      "Epoch 18, Batch 60, Loss 0.0003539975732564926\n",
      "Epoch 18, Batch 80, Loss 0.0003003106394317001\n",
      "Epoch 19, Batch 0, Loss 0.00033684479421935976\n",
      "Epoch 19, Batch 20, Loss 0.00030184900970198214\n",
      "Epoch 19, Batch 40, Loss 0.0005379322683438659\n",
      "Epoch 19, Batch 60, Loss 0.00029671727679669857\n",
      "Epoch 19, Batch 80, Loss 0.00032907750573940575\n",
      "Epoch 20, Batch 0, Loss 0.00031614647014066577\n",
      "Epoch 20, Batch 20, Loss 0.000273565441602841\n",
      "Epoch 20, Batch 40, Loss 0.0004617230442818254\n",
      "Epoch 20, Batch 60, Loss 0.0004296062688808888\n",
      "Epoch 20, Batch 80, Loss 0.0015083365142345428\n",
      "Epoch 21, Batch 0, Loss 0.00024015831877477467\n",
      "Epoch 21, Batch 20, Loss 0.00038218239205889404\n",
      "Epoch 21, Batch 40, Loss 0.0002742309879977256\n",
      "Epoch 21, Batch 60, Loss 0.0003918086877092719\n",
      "Epoch 21, Batch 80, Loss 0.0014268686063587666\n",
      "Epoch 22, Batch 0, Loss 0.00023444749240297824\n",
      "Epoch 22, Batch 20, Loss 0.0003270605520810932\n",
      "Epoch 22, Batch 40, Loss 0.00023462406534235924\n",
      "Epoch 22, Batch 60, Loss 0.00032432680018246174\n",
      "Epoch 22, Batch 80, Loss 0.000999677344225347\n",
      "Epoch 23, Batch 0, Loss 0.00019589414296206087\n",
      "Epoch 23, Batch 20, Loss 0.00032609733170829713\n",
      "Epoch 23, Batch 40, Loss 0.00046307119191624224\n",
      "Epoch 23, Batch 60, Loss 0.0004243774455972016\n",
      "Epoch 23, Batch 80, Loss 0.0002738382900133729\n",
      "Epoch 24, Batch 0, Loss 0.0007963634561747313\n",
      "Epoch 24, Batch 20, Loss 0.0002982479927595705\n",
      "Epoch 24, Batch 40, Loss 0.00028612418100237846\n",
      "Epoch 24, Batch 60, Loss 0.0003300459065940231\n",
      "Epoch 24, Batch 80, Loss 0.00032338930759578943\n",
      "Epoch 25, Batch 0, Loss 0.00037974060978740454\n",
      "Epoch 25, Batch 20, Loss 0.00026424400857649744\n",
      "Epoch 25, Batch 40, Loss 0.0003424867754802108\n",
      "Epoch 25, Batch 60, Loss 0.00034830556251108646\n",
      "Epoch 25, Batch 80, Loss 0.00020287552615627646\n",
      "Epoch 26, Batch 0, Loss 0.00029417010955512524\n",
      "Epoch 26, Batch 20, Loss 0.0002691094414331019\n",
      "Epoch 26, Batch 40, Loss 0.0004918370977975428\n",
      "Epoch 26, Batch 60, Loss 0.0003487596404738724\n",
      "Epoch 26, Batch 80, Loss 0.00048712739953771234\n",
      "Epoch 27, Batch 0, Loss 0.00023233745014294982\n",
      "Epoch 27, Batch 20, Loss 0.0004160737444180995\n",
      "Epoch 27, Batch 40, Loss 0.0006690020090900362\n",
      "Epoch 27, Batch 60, Loss 0.00135314860381186\n",
      "Epoch 27, Batch 80, Loss 0.00038336042780429125\n",
      "Epoch 28, Batch 0, Loss 0.00034403096651658416\n",
      "Epoch 28, Batch 20, Loss 0.00035140381078235805\n",
      "Epoch 28, Batch 40, Loss 0.0007080438081175089\n",
      "Epoch 28, Batch 60, Loss 0.0014616205589845777\n",
      "Epoch 28, Batch 80, Loss 0.0003172874276060611\n",
      "Epoch 29, Batch 0, Loss 0.00030065816827118397\n",
      "Epoch 29, Batch 20, Loss 0.0002668261295184493\n",
      "Epoch 29, Batch 40, Loss 0.0005783222732134163\n",
      "Epoch 29, Batch 60, Loss 0.0003012457746081054\n",
      "Epoch 29, Batch 80, Loss 0.00028818679857067764\n",
      "Epoch 30, Batch 0, Loss 0.0004648417525459081\n",
      "Epoch 30, Batch 20, Loss 0.0002766544057521969\n",
      "Epoch 30, Batch 40, Loss 0.0003011781955137849\n",
      "Epoch 30, Batch 60, Loss 0.00035364137147553265\n",
      "Epoch 30, Batch 80, Loss 0.00031683495035395026\n",
      "Epoch 31, Batch 0, Loss 0.0003020353615283966\n",
      "Epoch 31, Batch 20, Loss 0.00026397264446131885\n",
      "Epoch 31, Batch 40, Loss 0.0002836446219589561\n",
      "Epoch 31, Batch 60, Loss 0.000286339083686471\n",
      "Epoch 31, Batch 80, Loss 0.00024951653904281557\n",
      "Epoch 32, Batch 0, Loss 0.0004471699649002403\n",
      "Epoch 32, Batch 20, Loss 0.00038407035754062235\n",
      "Epoch 32, Batch 40, Loss 0.0003318542439956218\n",
      "Epoch 32, Batch 60, Loss 0.00032384629594162107\n",
      "Epoch 32, Batch 80, Loss 0.0004557596694212407\n",
      "Epoch 33, Batch 0, Loss 0.0004516966000664979\n",
      "Epoch 33, Batch 20, Loss 0.0008670305251143873\n",
      "Epoch 33, Batch 40, Loss 0.0002848170988727361\n",
      "Epoch 33, Batch 60, Loss 0.0008471702458336949\n",
      "Epoch 33, Batch 80, Loss 0.0002728164254222065\n",
      "Epoch 34, Batch 0, Loss 0.0002718774485401809\n",
      "Epoch 34, Batch 20, Loss 0.0005017563817091286\n",
      "Epoch 34, Batch 40, Loss 0.00021453220688272268\n",
      "Epoch 34, Batch 60, Loss 0.0003969765384681523\n",
      "Epoch 34, Batch 80, Loss 0.0009351480985060334\n",
      "Epoch 35, Batch 0, Loss 0.00030300815706141293\n",
      "Epoch 35, Batch 20, Loss 0.00040913376142270863\n",
      "Epoch 35, Batch 40, Loss 0.0003525596985127777\n",
      "Epoch 35, Batch 60, Loss 0.00033367378637194633\n",
      "Epoch 35, Batch 80, Loss 0.00028960173949599266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch 0, Loss 0.0015290678711608052\n",
      "Epoch 36, Batch 20, Loss 0.00040607177652418613\n",
      "Epoch 36, Batch 40, Loss 0.0003908427606802434\n",
      "Epoch 36, Batch 60, Loss 0.00029335578437894583\n",
      "Epoch 36, Batch 80, Loss 0.00040692303446121514\n",
      "Epoch 37, Batch 0, Loss 0.00027693953597918153\n",
      "Epoch 37, Batch 20, Loss 0.0014877233188599348\n",
      "Epoch 37, Batch 40, Loss 0.0002754738961812109\n",
      "Epoch 37, Batch 60, Loss 0.00045792327728122473\n",
      "Epoch 37, Batch 80, Loss 0.0003056888817809522\n",
      "Epoch 38, Batch 0, Loss 0.0004344023473095149\n",
      "Epoch 38, Batch 20, Loss 0.0002203289041062817\n",
      "Epoch 38, Batch 40, Loss 0.0002881785330828279\n",
      "Epoch 38, Batch 60, Loss 0.0007842259365133941\n",
      "Epoch 38, Batch 80, Loss 0.0005404292605817318\n",
      "Epoch 39, Batch 0, Loss 0.00043660664232447743\n",
      "Epoch 39, Batch 20, Loss 0.00032409184495918453\n",
      "Epoch 39, Batch 40, Loss 0.0003904725017491728\n",
      "Epoch 39, Batch 60, Loss 0.00039914780063554645\n",
      "Epoch 39, Batch 80, Loss 0.0002900398976635188\n",
      "Epoch 40, Batch 0, Loss 0.0002769621496554464\n",
      "Epoch 40, Batch 20, Loss 0.000384834740543738\n",
      "Epoch 40, Batch 40, Loss 0.0006563212955370545\n",
      "Epoch 40, Batch 60, Loss 0.00030254421290010214\n",
      "Epoch 40, Batch 80, Loss 0.0003337269008625299\n",
      "Epoch 41, Batch 0, Loss 0.0017257751896977425\n",
      "Epoch 41, Batch 20, Loss 0.00021360033133532852\n",
      "Epoch 41, Batch 40, Loss 0.0003932260151486844\n",
      "Epoch 41, Batch 60, Loss 0.0004524323157966137\n",
      "Epoch 41, Batch 80, Loss 0.00030920817516744137\n",
      "Epoch 42, Batch 0, Loss 0.0004215789376758039\n",
      "Epoch 42, Batch 20, Loss 0.0008235180284827948\n",
      "Epoch 42, Batch 40, Loss 0.00042480151751078665\n",
      "Epoch 42, Batch 60, Loss 0.00037529304972849786\n",
      "Epoch 42, Batch 80, Loss 0.00042464540456421673\n",
      "Epoch 43, Batch 0, Loss 0.000311011855956167\n",
      "Epoch 43, Batch 20, Loss 0.0007941295043565333\n",
      "Epoch 43, Batch 40, Loss 0.00018549856031313539\n",
      "Epoch 43, Batch 60, Loss 0.0002622981264721602\n",
      "Epoch 43, Batch 80, Loss 0.00035878672497346997\n",
      "Epoch 44, Batch 0, Loss 0.00023348147806245834\n",
      "Epoch 44, Batch 20, Loss 0.0003254451439715922\n",
      "Epoch 44, Batch 40, Loss 0.0005542853032238781\n",
      "Epoch 44, Batch 60, Loss 0.00032443288364447653\n",
      "Epoch 44, Batch 80, Loss 0.00035224316525273025\n",
      "Epoch 45, Batch 0, Loss 0.00026328724925406277\n",
      "Epoch 45, Batch 20, Loss 0.00047324554179795086\n",
      "Epoch 45, Batch 40, Loss 0.0003386774624232203\n",
      "Epoch 45, Batch 60, Loss 0.0003953144187107682\n",
      "Epoch 45, Batch 80, Loss 0.00033292986336164176\n",
      "Epoch 46, Batch 0, Loss 0.00031739225960336626\n",
      "Epoch 46, Batch 20, Loss 0.0003595382731873542\n",
      "Epoch 46, Batch 40, Loss 0.0007367748767137527\n",
      "Epoch 46, Batch 60, Loss 0.00025014550192281604\n",
      "Epoch 46, Batch 80, Loss 0.0005779032944701612\n",
      "Epoch 47, Batch 0, Loss 0.00033549690851941705\n",
      "Epoch 47, Batch 20, Loss 0.00042528269113972783\n",
      "Epoch 47, Batch 40, Loss 0.0006638195482082665\n",
      "Epoch 47, Batch 60, Loss 0.00035105625283904374\n",
      "Epoch 47, Batch 80, Loss 0.000406889506848529\n",
      "Epoch 48, Batch 0, Loss 0.0005264537176117301\n",
      "Epoch 48, Batch 20, Loss 0.00036392980837263167\n",
      "Epoch 48, Batch 40, Loss 0.00032670103246346116\n",
      "Epoch 48, Batch 60, Loss 0.0005587945342995226\n",
      "Epoch 48, Batch 80, Loss 0.0010049132397398353\n",
      "Epoch 49, Batch 0, Loss 0.00043320213444530964\n",
      "Epoch 49, Batch 20, Loss 0.0009771964978426695\n",
      "Epoch 49, Batch 40, Loss 0.00048643903573974967\n",
      "Epoch 49, Batch 60, Loss 0.0003720210224855691\n",
      "Epoch 49, Batch 80, Loss 0.0003840966382995248\n"
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "def train_model(model, dataloader, epochs):\n",
    "    min_loss = float('inf')  # 初始最小损失设为正无穷大\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (seq, target) in enumerate(dataloader):\n",
    "            seq = seq.to(device).float()\n",
    "            target = target.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            seq = seq.view(-1, 7, 29)  # Reshape to (batch_size * num_stocks, time_step, input_dim)\n",
    "#             print(seq.shape)  #  [5984, 7, 30]\n",
    "            target = target.view(-1,1)  # Flatten target to have shape (batch_size * num_stocks)\n",
    "#             print(target.shape)  #  [5984, 1]\n",
    "            attention_vec, attention_probs = model(seq)\n",
    "            attention_vec = attention_vec.squeeze()  # Remove extra dimensions to match target shape\n",
    "            loss = criterion(attention_vec, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss {loss.item()}')\n",
    "        if loss.item() < min_loss:  # 当前损失小于记录的最小损失就保存\n",
    "            min_loss = loss.item() \n",
    "            torch.save(model, './output/sequence_encoder-1202.pkl') \n",
    "            print('save!')\n",
    "\n",
    "# 开始训练\n",
    "train_model(sequence_encoder, dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac046d-d766-4ec6-894b-a50a2c9103c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:36:25.186923Z",
     "iopub.status.busy": "2023-11-26T07:36:25.186487Z",
     "iopub.status.idle": "2023-11-26T07:36:25.191362Z",
     "shell.execute_reply": "2023-11-26T07:36:25.190259Z",
     "shell.execute_reply.started": "2023-11-26T07:36:25.186884Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 测试数据，加载node和edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27f3465f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:50:51.105004Z",
     "iopub.status.busy": "2023-11-28T09:50:51.104292Z",
     "iopub.status.idle": "2023-11-28T09:50:51.110622Z",
     "shell.execute_reply": "2023-11-28T09:50:51.109705Z",
     "shell.execute_reply.started": "2023-11-28T09:50:51.104966Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 475, 7, 29)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e732dd8-a6bc-4e65-827a-0152f3d73fb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:46:02.389862Z",
     "iopub.status.busy": "2023-11-28T09:46:02.389436Z",
     "iopub.status.idle": "2023-11-28T09:46:02.395059Z",
     "shell.execute_reply": "2023-11-28T09:46:02.394566Z",
     "shell.execute_reply.started": "2023-11-28T09:46:02.389820Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 475)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa560b62-43de-45a1-8d00-6efec1c020df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:48:57.909349Z",
     "iopub.status.busy": "2023-11-28T09:48:57.909100Z",
     "iopub.status.idle": "2023-11-28T09:48:57.913132Z",
     "shell.execute_reply": "2023-11-28T09:48:57.912572Z",
     "shell.execute_reply.started": "2023-11-28T09:48:57.909328Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 7, 29)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test_x[0,:,:,:]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8ef1d23-380d-4812-917c-5054f0540af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:49:30.047642Z",
     "iopub.status.busy": "2023-11-28T09:49:30.047356Z",
     "iopub.status.idle": "2023-11-28T09:49:30.077463Z",
     "shell.execute_reply": "2023-11-28T09:49:30.076994Z",
     "shell.execute_reply.started": "2023-11-28T09:49:30.047621Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([475, 7, 29])\n",
      "torch.Size([475, 1, 64])\n",
      "torch.Size([475, 7, 64])\n"
     ]
    }
   ],
   "source": [
    "# torch.Size([16, 480, 7, 29])\n",
    "# torch.Size([16, 480])\n",
    "new_week_data = test_x[0,:,:,:]\n",
    "# 评估模型\n",
    "sequence_encoder.eval()\n",
    "\n",
    "# 不需要计算梯度\n",
    "with torch.no_grad():\n",
    "    input = torch.Tensor(new_week_data).view(-1,7,29).to(device)\n",
    "    print(input.size())\n",
    "    attention_vecs, attention_probs = sequence_encoder(input)\n",
    "    print(attention_vecs.size())\n",
    "    print(attention_probs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55d6f73c-8303-41ed-9db8-c0cd0268d7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:08.684504Z",
     "iopub.status.busy": "2023-11-28T09:52:08.684054Z",
     "iopub.status.idle": "2023-11-28T09:52:08.691157Z",
     "shell.execute_reply": "2023-11-28T09:52:08.690101Z",
     "shell.execute_reply.started": "2023-11-28T09:52:08.684462Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([475, 1, 64])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vecs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75c9d688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:13.354589Z",
     "iopub.status.busy": "2023-11-28T09:52:13.354213Z",
     "iopub.status.idle": "2023-11-28T09:52:13.365962Z",
     "shell.execute_reply": "2023-11-28T09:52:13.365352Z",
     "shell.execute_reply.started": "2023-11-28T09:52:13.354565Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,  23],\n",
       "       [  0,  25],\n",
       "       ...,\n",
       "       [426, 426],\n",
       "       [426, 447],\n",
       "       [447, 447]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge = np.array(np.load(\"./datasets3/inner_edge.npy\"))\n",
    "inner_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b44f371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:16.619168Z",
     "iopub.status.busy": "2023-11-28T09:52:16.618353Z",
     "iopub.status.idle": "2023-11-28T09:52:16.645614Z",
     "shell.execute_reply": "2023-11-28T09:52:16.644592Z",
     "shell.execute_reply.started": "2023-11-28T09:52:16.619124Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 426, 426, 447],\n",
       "        [  0,  23,  25,  ..., 426, 447, 447]], device='cuda:0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge = torch.tensor(inner_edge.T, dtype=torch.int64).to(device)\n",
    "inner_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "294e50f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:19.938363Z",
     "iopub.status.busy": "2023-11-28T09:52:19.938157Z",
     "iopub.status.idle": "2023-11-28T09:52:19.942949Z",
     "shell.execute_reply": "2023-11-28T09:52:19.942238Z",
     "shell.execute_reply.started": "2023-11-28T09:52:19.938343Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9945])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe89a3-8dbc-4e34-b9e9-2a0e6d9a18bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:37:19.380726Z",
     "iopub.status.busy": "2023-11-26T07:37:19.380348Z",
     "iopub.status.idle": "2023-11-26T07:37:19.383658Z",
     "shell.execute_reply": "2023-11-26T07:37:19.382881Z",
     "shell.execute_reply.started": "2023-11-26T07:37:19.380700Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 一周内、不同股票间的gat代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "23a3888a-5fd4-4a27-b263-12feaa43663d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:27.893935Z",
     "iopub.status.busy": "2023-11-28T09:52:27.893654Z",
     "iopub.status.idle": "2023-11-28T09:52:27.901889Z",
     "shell.execute_reply": "2023-11-28T09:52:27.901193Z",
     "shell.execute_reply.started": "2023-11-28T09:52:27.893909Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(hidden_dim,hidden_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 输入层\n",
    "        x, attention_weights = self.conv1(x, edge_index, return_attention_weights=True)\n",
    "        x = F.elu(x)\n",
    "\n",
    "        return x, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "50bf56c3-eab6-402c-b2b5-e363cf767b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:34.178902Z",
     "iopub.status.busy": "2023-11-28T09:52:34.178638Z",
     "iopub.status.idle": "2023-11-28T09:52:34.255095Z",
     "shell.execute_reply": "2023-11-28T09:52:34.254591Z",
     "shell.execute_reply.started": "2023-11-28T09:52:34.178881Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([475, 64])\n",
      "torch.Size([2, 9945])\n"
     ]
    }
   ],
   "source": [
    "# node和edge\n",
    "nodes = attention_vecs.squeeze(1)  # 假设这是你的节点特征\n",
    "print(nodes.size())\n",
    "edges = inner_edge  # 假设这是你的边索引\n",
    "print(edges.size())\n",
    "\n",
    "# 创建模型\n",
    "hidden_num = 64\n",
    "model = GATModel(hidden_num).to(device)\n",
    "\n",
    "# 前向传播\n",
    "model.train()\n",
    "out, gat_attention = model(nodes, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4210dd5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:52:35.801936Z",
     "iopub.status.busy": "2023-11-28T09:52:35.801749Z",
     "iopub.status.idle": "2023-11-28T09:52:35.805960Z",
     "shell.execute_reply": "2023-11-28T09:52:35.805193Z",
     "shell.execute_reply.started": "2023-11-28T09:52:35.801917Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([475, 64])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed414062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   0,   0,  ..., 472, 473, 474],\n",
       "         [ 23,  25,  26,  ..., 472, 473, 474]], device='cuda:0'),\n",
       " tensor([[0.5009],\n",
       "         [0.3342],\n",
       "         [0.2507],\n",
       "         ...,\n",
       "         [0.0333],\n",
       "         [0.0227],\n",
       "         [0.0833]], device='cuda:0', grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "96d59f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9945, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_attention[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c26a1f-7e46-4215-b3eb-336e2050582e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:53:55.604943Z",
     "iopub.status.busy": "2023-11-28T09:53:55.604498Z",
     "iopub.status.idle": "2023-11-28T09:53:55.609332Z",
     "shell.execute_reply": "2023-11-28T09:53:55.608310Z",
     "shell.execute_reply.started": "2023-11-28T09:53:55.604901Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 遍历每周gat图得到g_i和a_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9281aa79-ef74-443f-922a-a2b2a2e79d41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T09:56:44.959008Z",
     "iopub.status.busy": "2023-11-28T09:56:44.958729Z",
     "iopub.status.idle": "2023-11-28T09:56:44.983081Z",
     "shell.execute_reply": "2023-11-28T09:56:44.982499Z",
     "shell.execute_reply.started": "2023-11-28T09:56:44.958982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 426, 426, 447],\n",
       "        [  0,  23,  25,  ..., 426, 447, 447]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge = np.array(np.load(\"/openbayes/input/input0/inner_edge.npy\"))\n",
    "inner_edge = torch.tensor(inner_edge.T, dtype=torch.int64).to(device)\n",
    "inner_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd1c08ba-3394-40da-95d5-1d6cc824eeda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:14:35.957298Z",
     "iopub.status.busy": "2023-11-28T10:14:35.956634Z",
     "iopub.status.idle": "2023-11-28T10:14:35.960880Z",
     "shell.execute_reply": "2023-11-28T10:14:35.960426Z",
     "shell.execute_reply.started": "2023-11-28T10:14:35.957273Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = torch.load('./output/sequence_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e794864-343c-47c7-ab07-77cc9ae158a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:03:11.151953Z",
     "iopub.status.busy": "2023-11-28T10:03:11.151714Z",
     "iopub.status.idle": "2023-11-28T10:03:11.157130Z",
     "shell.execute_reply": "2023-11-28T10:03:11.156236Z",
     "shell.execute_reply.started": "2023-11-28T10:03:11.151931Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 480, 7, 29)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25d464b1-84bc-4620-8d1a-9fa0831fb84e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:23:27.380557Z",
     "iopub.status.busy": "2023-11-28T10:23:27.380112Z",
     "iopub.status.idle": "2023-11-28T10:23:28.852071Z",
     "shell.execute_reply": "2023-11-28T10:23:28.851500Z",
     "shell.execute_reply.started": "2023-11-28T10:23:27.380514Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gat_result = {}\n",
    "encoder_result = {}\n",
    "for i in range(test_x.shape[0]):  # test_x.shape[0]\n",
    "    week_data = torch.Tensor(test_x[i,:,:,:]).view(-1,7,29).to(device)\n",
    "    attention_vecs, attention_probs = best_model(week_data)\n",
    "    encoder_result[f'test_week{i+1}'] = attention_vecs.squeeze(1).detach().cpu().numpy()\n",
    "    nodes = attention_vecs.squeeze(1)\n",
    "    # print(nodes.size())\n",
    "    edges = inner_edge  # 假设这是你的边索引\n",
    "    # print(edges.size())\n",
    "    gat = GATModel(num_node_features=64, num_hidden_units=8, num_classes=8).to(device)\n",
    "    # 前向传播\n",
    "    gat.train()\n",
    "    out = gat(nodes, edges)\n",
    "    gat_result[f'test_week{i+1}'] = out.detach().cpu().numpy()\n",
    "    # print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "755d49f7-f8d7-4569-85c4-32037698aa94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:23:30.215300Z",
     "iopub.status.busy": "2023-11-28T10:23:30.214947Z",
     "iopub.status.idle": "2023-11-28T10:23:30.219023Z",
     "shell.execute_reply": "2023-11-28T10:23:30.218611Z",
     "shell.execute_reply.started": "2023-11-28T10:23:30.215281Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gat_result['test_week1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e003728b-5b29-4d52-b234-7d8125bf8103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:23:30.889633Z",
     "iopub.status.busy": "2023-11-28T10:23:30.889269Z",
     "iopub.status.idle": "2023-11-28T10:23:30.895307Z",
     "shell.execute_reply": "2023-11-28T10:23:30.894522Z",
     "shell.execute_reply.started": "2023-11-28T10:23:30.889594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_result['test_week1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e893894c-19ed-47e7-b2a4-6f3a944f1834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-28T10:25:44.205839Z",
     "iopub.status.busy": "2023-11-28T10:25:44.205405Z",
     "iopub.status.idle": "2023-11-28T10:25:44.282031Z",
     "shell.execute_reply": "2023-11-28T10:25:44.281448Z",
     "shell.execute_reply.started": "2023-11-28T10:25:44.205796Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./output/g_i.pkl', 'wb') as file:\n",
    "    pickle.dump(gat_result, file)\n",
    "file.close()\n",
    "\n",
    "with open('./output/a_i.pkl', 'wb') as file:\n",
    "    pickle.dump(encoder_result, file)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-py3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
