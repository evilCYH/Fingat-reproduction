{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bed0ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:09.618285Z",
     "iopub.status.busy": "2023-11-26T07:49:09.617638Z",
     "iopub.status.idle": "2023-11-26T07:49:09.625130Z",
     "shell.execute_reply": "2023-11-26T07:49:09.624115Z",
     "shell.execute_reply.started": "2023-11-26T07:49:09.618235Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, SAGPooling,global_mean_pool , global_max_pool \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749bdbc4-e851-40f2-9800-32104754a1ea",
   "metadata": {},
   "source": [
    "## fingat源码的关于编码的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7d270cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:11.269942Z",
     "iopub.status.busy": "2023-11-26T07:49:11.269552Z",
     "iopub.status.idle": "2023-11-26T07:49:11.281247Z",
     "shell.execute_reply": "2023-11-26T07:49:11.280156Z",
     "shell.execute_reply.started": "2023-11-26T07:49:11.269902Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self,time_step,dim):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.attention_matrix = nn.Linear(time_step, time_step)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs_t = torch.transpose(inputs,2,1) # (batch_size, input_dim, time_step)\n",
    "        attention_weight = self.attention_matrix(inputs_t)\n",
    "        attention_probs = F.softmax(attention_weight,dim=-1)\n",
    "        attention_probs = torch.transpose(attention_probs,2,1)\n",
    "        attention_vec = torch.mul(attention_probs, inputs)\n",
    "        attention_vec = torch.sum(attention_vec,dim=1)\n",
    "        return attention_vec, attention_probs\n",
    "\n",
    "class SequenceEncoder(nn.Module):\n",
    "    def __init__(self,input_dim,time_step,hidden_dim):\n",
    "        super(SequenceEncoder, self).__init__()\n",
    "        self.encoder = nn.GRU(input_size=input_dim,hidden_size=hidden_dim,num_layers=1,batch_first=True)\n",
    "        self.attention_block = AttentionBlock(time_step,hidden_dim) \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.dim = hidden_dim\n",
    "    \n",
    "    def forward(self,seq):\n",
    "        '''\n",
    "        inp : torch.tensor (batch,time_step,input_dim)\n",
    "        '''\n",
    "        seq_vector,_ = self.encoder(seq)\n",
    "        seq_vector = self.dropout(seq_vector)\n",
    "        attention_vec, attention_probs = self.attention_block(seq_vector)\n",
    "        attention_vec = attention_vec.view(-1,1,self.dim) # prepare for concat\n",
    "        return attention_vec, attention_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603a489-7b12-47da-a057-ba6fb13d903d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:32:24.953710Z",
     "iopub.status.busy": "2023-11-26T07:32:24.953283Z",
     "iopub.status.idle": "2023-11-26T07:32:24.958082Z",
     "shell.execute_reply": "2023-11-26T07:32:24.956965Z",
     "shell.execute_reply.started": "2023-11-26T07:32:24.953670Z"
    },
    "tags": []
   },
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c451532d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T06:53:41.875195Z",
     "iopub.status.busy": "2023-11-26T06:53:41.874703Z",
     "iopub.status.idle": "2023-11-26T06:53:55.462563Z",
     "shell.execute_reply": "2023-11-26T06:53:55.461471Z",
     "shell.execute_reply.started": "2023-11-26T06:53:41.875153Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./datasets/sp500_data.pkl', \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae43f7b-cde2-47ac-b99f-39d8f0367bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:18.270491Z",
     "iopub.status.busy": "2023-11-26T07:49:18.270076Z",
     "iopub.status.idle": "2023-11-26T07:49:18.275471Z",
     "shell.execute_reply": "2023-11-26T07:49:18.274428Z",
     "shell.execute_reply.started": "2023-11-26T07:49:18.270451Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61512cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:19.249625Z",
     "iopub.status.busy": "2023-11-26T07:49:19.249417Z",
     "iopub.status.idle": "2023-11-26T07:49:19.254303Z",
     "shell.execute_reply": "2023-11-26T07:49:19.253799Z",
     "shell.execute_reply.started": "2023-11-26T07:49:19.249605Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1580, 480, 7, 29)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = data['train']['x1'][:,:,:,1:]\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aae0f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 480, 7, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = data['test']['x1'][:,:,:,1:]\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8744be9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:20.317800Z",
     "iopub.status.busy": "2023-11-26T07:49:20.317420Z",
     "iopub.status.idle": "2023-11-26T07:49:20.323846Z",
     "shell.execute_reply": "2023-11-26T07:49:20.323344Z",
     "shell.execute_reply.started": "2023-11-26T07:49:20.317762Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1580, 480)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = data['train']['y_return ratio']\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e1f5912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 480)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y = data['test']['y_return ratio']\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287c60f-46ab-4685-8226-aeb65bc8dcc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:32:49.001429Z",
     "iopub.status.busy": "2023-11-26T07:32:49.000994Z",
     "iopub.status.idle": "2023-11-26T07:32:49.005612Z",
     "shell.execute_reply": "2023-11-26T07:32:49.004810Z",
     "shell.execute_reply.started": "2023-11-26T07:32:49.001389Z"
    },
    "tags": []
   },
   "source": [
    "## 设立pytorch的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de5ad44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:22.389307Z",
     "iopub.status.busy": "2023-11-26T07:49:22.388931Z",
     "iopub.status.idle": "2023-11-26T07:49:22.396886Z",
     "shell.execute_reply": "2023-11-26T07:49:22.395996Z",
     "shell.execute_reply.started": "2023-11-26T07:49:22.389269Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "def create_dataloader(x, y, batch_size):\n",
    "    dataset = StockDataset(x, y)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48c4d7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:23.756033Z",
     "iopub.status.busy": "2023-11-26T07:49:23.755545Z",
     "iopub.status.idle": "2023-11-26T07:49:23.761200Z",
     "shell.execute_reply": "2023-11-26T07:49:23.760239Z",
     "shell.execute_reply.started": "2023-11-26T07:49:23.755979Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = create_dataloader(train_x, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd7e2a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:24.637666Z",
     "iopub.status.busy": "2023-11-26T07:49:24.637284Z",
     "iopub.status.idle": "2023-11-26T07:49:24.806079Z",
     "shell.execute_reply": "2023-11-26T07:49:24.805581Z",
     "shell.execute_reply.started": "2023-11-26T07:49:24.637628Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "1\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "2\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "3\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "4\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "5\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "6\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "7\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "8\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "9\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "10\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "11\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "12\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "13\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "14\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "15\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "16\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "17\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "18\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "19\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "20\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "21\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "22\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "23\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "24\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "25\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "26\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "27\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "28\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "29\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "30\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "31\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "32\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "33\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "34\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "35\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "36\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "37\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "38\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "39\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "40\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "41\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "42\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "43\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "44\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "45\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "46\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "47\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "48\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "49\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "50\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "51\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "52\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "53\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "54\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "55\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "56\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "57\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "58\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "59\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "60\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "61\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "62\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "63\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "64\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "65\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "66\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "67\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "68\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "69\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "70\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "71\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "72\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "73\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "74\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "75\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "76\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "77\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "78\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "79\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "80\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "81\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "82\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "83\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "84\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "85\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "86\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "87\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "88\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "89\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "90\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "91\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "92\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "93\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "94\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "95\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "96\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "97\n",
      "torch.Size([16, 480, 7, 29])\n",
      "torch.Size([16, 480])\n",
      "=========================\n",
      "98\n",
      "torch.Size([12, 480, 7, 29])\n",
      "torch.Size([12, 480])\n",
      "=========================\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (seq, target) in enumerate(dataloader):\n",
    "    print(batch_idx)\n",
    "    print(seq.shape)\n",
    "    print(target.shape)\n",
    "    print(\"=========================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e9054-8289-4ffb-ab42-bbaed1735381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:33:44.456985Z",
     "iopub.status.busy": "2023-11-26T07:33:44.456659Z",
     "iopub.status.idle": "2023-11-26T07:33:44.459472Z",
     "shell.execute_reply": "2023-11-26T07:33:44.458982Z",
     "shell.execute_reply.started": "2023-11-26T07:33:44.456966Z"
    },
    "tags": []
   },
   "source": [
    "## 建立模型，设置优化器、损失，进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2815be93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:29.429409Z",
     "iopub.status.busy": "2023-11-26T07:49:29.429160Z",
     "iopub.status.idle": "2023-11-26T07:49:29.434494Z",
     "shell.execute_reply": "2023-11-26T07:49:29.433653Z",
     "shell.execute_reply.started": "2023-11-26T07:49:29.429390Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 建立\n",
    "sequence_encoder = SequenceEncoder(input_dim=29, time_step=7, hidden_dim=64)\n",
    "\n",
    "# 定义损失和优化\n",
    "criterion = nn.MSELoss()  # 因为是回归问题，所以我们使用均方误差损失\n",
    "optimizer = Adam(sequence_encoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f801e09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:49:30.396997Z",
     "iopub.status.busy": "2023-11-26T07:49:30.396175Z",
     "iopub.status.idle": "2023-11-26T07:51:02.858850Z",
     "shell.execute_reply": "2023-11-26T07:51:02.858173Z",
     "shell.execute_reply.started": "2023-11-26T07:49:30.396954Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([7680, 1])) that is different to the input size (torch.Size([7680, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss 0.0099116126075387\n",
      "Epoch 0, Batch 20, Loss 0.0043643685057759285\n",
      "Epoch 0, Batch 40, Loss 0.0029200019780546427\n",
      "Epoch 0, Batch 60, Loss 0.001389387296512723\n",
      "Epoch 0, Batch 80, Loss 0.0008254718268290162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([5760, 1])) that is different to the input size (torch.Size([5760, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save!\n",
      "Epoch 1, Batch 0, Loss 0.0009037769632413983\n",
      "Epoch 1, Batch 20, Loss 0.0006938229780644178\n",
      "Epoch 1, Batch 40, Loss 0.0003547155938576907\n",
      "Epoch 1, Batch 60, Loss 0.00046185782412067056\n",
      "Epoch 1, Batch 80, Loss 0.00030233271536417305\n",
      "save!\n",
      "Epoch 2, Batch 0, Loss 0.0004561389214359224\n",
      "Epoch 2, Batch 20, Loss 0.0003709917073138058\n",
      "Epoch 2, Batch 40, Loss 0.0002968697517644614\n",
      "Epoch 2, Batch 60, Loss 0.0003529299283400178\n",
      "Epoch 2, Batch 80, Loss 0.0002861999091692269\n",
      "Epoch 3, Batch 0, Loss 0.00045825602137483656\n",
      "Epoch 3, Batch 20, Loss 0.00035936152562499046\n",
      "Epoch 3, Batch 40, Loss 0.00032564232242293656\n",
      "Epoch 3, Batch 60, Loss 0.0005724569200538099\n",
      "Epoch 3, Batch 80, Loss 0.0003526262880768627\n",
      "Epoch 4, Batch 0, Loss 0.0003190336574334651\n",
      "Epoch 4, Batch 20, Loss 0.0003191427676938474\n",
      "Epoch 4, Batch 40, Loss 0.00027990969829261303\n",
      "Epoch 4, Batch 60, Loss 0.0005514786462299526\n",
      "Epoch 4, Batch 80, Loss 0.00036044197622686625\n",
      "Epoch 5, Batch 0, Loss 0.0003257881908211857\n",
      "Epoch 5, Batch 20, Loss 0.00024998924345709383\n",
      "Epoch 5, Batch 40, Loss 0.0005804874235764146\n",
      "Epoch 5, Batch 60, Loss 0.00027118256548419595\n",
      "Epoch 5, Batch 80, Loss 0.0004836578737013042\n",
      "Epoch 6, Batch 0, Loss 0.00039517658296972513\n",
      "Epoch 6, Batch 20, Loss 0.00026232600794173777\n",
      "Epoch 6, Batch 40, Loss 0.0011509864125400782\n",
      "Epoch 6, Batch 60, Loss 0.0002463635755702853\n",
      "Epoch 6, Batch 80, Loss 0.00027121807215735316\n",
      "Epoch 7, Batch 0, Loss 0.0003291963948868215\n",
      "Epoch 7, Batch 20, Loss 0.00036243480280973017\n",
      "Epoch 7, Batch 40, Loss 0.0005641118041239679\n",
      "Epoch 7, Batch 60, Loss 0.00035797577584162354\n",
      "Epoch 7, Batch 80, Loss 0.0005320341442711651\n",
      "Epoch 8, Batch 0, Loss 0.00023034073819871992\n",
      "Epoch 8, Batch 20, Loss 0.00031954963924363256\n",
      "Epoch 8, Batch 40, Loss 0.00035546586150303483\n",
      "Epoch 8, Batch 60, Loss 0.00033862164127640426\n",
      "Epoch 8, Batch 80, Loss 0.0004246989556122571\n",
      "Epoch 9, Batch 0, Loss 0.0003098515735473484\n",
      "Epoch 9, Batch 20, Loss 0.00026237370911985636\n",
      "Epoch 9, Batch 40, Loss 0.00024172358098439872\n",
      "Epoch 9, Batch 60, Loss 0.0003086591314058751\n",
      "Epoch 9, Batch 80, Loss 0.00031655377824790776\n",
      "Epoch 10, Batch 0, Loss 0.0002530314668547362\n",
      "Epoch 10, Batch 20, Loss 0.000260787783190608\n",
      "Epoch 10, Batch 40, Loss 0.0004164168203715235\n",
      "Epoch 10, Batch 60, Loss 0.0003458471328485757\n",
      "Epoch 10, Batch 80, Loss 0.00041119707748293877\n",
      "save!\n",
      "Epoch 11, Batch 0, Loss 0.00036773935426026583\n",
      "Epoch 11, Batch 20, Loss 0.00039647927042096853\n",
      "Epoch 11, Batch 40, Loss 0.00028325177845545113\n",
      "Epoch 11, Batch 60, Loss 0.0006707807769998908\n",
      "Epoch 11, Batch 80, Loss 0.0003249294531997293\n",
      "Epoch 12, Batch 0, Loss 0.00030825118301436305\n",
      "Epoch 12, Batch 20, Loss 0.00047608520253561437\n",
      "Epoch 12, Batch 40, Loss 0.0002723301586229354\n",
      "Epoch 12, Batch 60, Loss 0.0007732327794656157\n",
      "Epoch 12, Batch 80, Loss 0.00021164964709896594\n",
      "Epoch 13, Batch 0, Loss 0.0009111058316193521\n",
      "Epoch 13, Batch 20, Loss 0.001526384730823338\n",
      "Epoch 13, Batch 40, Loss 0.000247385585680604\n",
      "Epoch 13, Batch 60, Loss 0.00033747832640074193\n",
      "Epoch 13, Batch 80, Loss 0.0004480418283492327\n",
      "Epoch 14, Batch 0, Loss 0.0004301411099731922\n",
      "Epoch 14, Batch 20, Loss 0.0005888738669455051\n",
      "Epoch 14, Batch 40, Loss 0.00042254384607076645\n",
      "Epoch 14, Batch 60, Loss 0.0007251906208693981\n",
      "Epoch 14, Batch 80, Loss 0.00026424217503517866\n",
      "Epoch 15, Batch 0, Loss 0.00030636036535725\n",
      "Epoch 15, Batch 20, Loss 0.0002904908324126154\n",
      "Epoch 15, Batch 40, Loss 0.0003800636332016438\n",
      "Epoch 15, Batch 60, Loss 0.0003745321009773761\n",
      "Epoch 15, Batch 80, Loss 0.0004465447273105383\n",
      "Epoch 16, Batch 0, Loss 0.00045884159044362605\n",
      "Epoch 16, Batch 20, Loss 0.00044963142136111856\n",
      "Epoch 16, Batch 40, Loss 0.0003296602808404714\n",
      "Epoch 16, Batch 60, Loss 0.0002854017657227814\n",
      "Epoch 16, Batch 80, Loss 0.00028457067674025893\n",
      "Epoch 17, Batch 0, Loss 0.00028376339469105005\n",
      "Epoch 17, Batch 20, Loss 0.0005558429402299225\n",
      "Epoch 17, Batch 40, Loss 0.0003346429148223251\n",
      "Epoch 17, Batch 60, Loss 0.0003527537046466023\n",
      "Epoch 17, Batch 80, Loss 0.0003454052784945816\n",
      "Epoch 18, Batch 0, Loss 0.0004247234028298408\n",
      "Epoch 18, Batch 20, Loss 0.0004389033711049706\n",
      "Epoch 18, Batch 40, Loss 0.0002696785086300224\n",
      "Epoch 18, Batch 60, Loss 0.0017922674305737019\n",
      "Epoch 18, Batch 80, Loss 0.00025380420265719295\n",
      "Epoch 19, Batch 0, Loss 0.00032214977545663714\n",
      "Epoch 19, Batch 20, Loss 0.0003108849632553756\n",
      "Epoch 19, Batch 40, Loss 0.0006956724682822824\n",
      "Epoch 19, Batch 60, Loss 0.0002582960878498852\n",
      "Epoch 19, Batch 80, Loss 0.0008916369988583028\n",
      "Epoch 20, Batch 0, Loss 0.0004071710864081979\n",
      "Epoch 20, Batch 20, Loss 0.0002344568638363853\n",
      "Epoch 20, Batch 40, Loss 0.0002627231297083199\n",
      "Epoch 20, Batch 60, Loss 0.0005730531411245465\n",
      "Epoch 20, Batch 80, Loss 0.0006607366958633065\n",
      "Epoch 21, Batch 0, Loss 0.000272840989055112\n",
      "Epoch 21, Batch 20, Loss 0.0004511955485213548\n",
      "Epoch 21, Batch 40, Loss 0.0002788804704323411\n",
      "Epoch 21, Batch 60, Loss 0.0009586732485331595\n",
      "Epoch 21, Batch 80, Loss 0.00029292519320733845\n",
      "Epoch 22, Batch 0, Loss 0.0005297551979310811\n",
      "Epoch 22, Batch 20, Loss 0.0003394122759345919\n",
      "Epoch 22, Batch 40, Loss 0.0003660833172034472\n",
      "Epoch 22, Batch 60, Loss 0.0016464564250782132\n",
      "Epoch 22, Batch 80, Loss 0.0005049055907875299\n",
      "Epoch 23, Batch 0, Loss 0.0003128464159090072\n",
      "Epoch 23, Batch 20, Loss 0.00022442977933678776\n",
      "Epoch 23, Batch 40, Loss 0.0004991639871150255\n",
      "Epoch 23, Batch 60, Loss 0.0003448998904787004\n",
      "Epoch 23, Batch 80, Loss 0.0002467407612130046\n",
      "Epoch 24, Batch 0, Loss 0.0003163215587846935\n",
      "Epoch 24, Batch 20, Loss 0.0003031067899428308\n",
      "Epoch 24, Batch 40, Loss 0.0003099885070696473\n",
      "Epoch 24, Batch 60, Loss 0.0005682383780367672\n",
      "Epoch 24, Batch 80, Loss 0.0004461286007426679\n",
      "Epoch 25, Batch 0, Loss 0.0004917003097943962\n",
      "Epoch 25, Batch 20, Loss 0.00038858409970998764\n",
      "Epoch 25, Batch 40, Loss 0.0003341957926750183\n",
      "Epoch 25, Batch 60, Loss 0.0002497535606380552\n",
      "Epoch 25, Batch 80, Loss 0.00034469785168766975\n",
      "Epoch 26, Batch 0, Loss 0.0004065744869876653\n",
      "Epoch 26, Batch 20, Loss 0.0002759029739536345\n",
      "Epoch 26, Batch 40, Loss 0.0006926591158844531\n",
      "Epoch 26, Batch 60, Loss 0.0003644863609224558\n",
      "Epoch 26, Batch 80, Loss 0.0014686955837532878\n",
      "Epoch 27, Batch 0, Loss 0.0004935633623972535\n",
      "Epoch 27, Batch 20, Loss 0.0017954657087102532\n",
      "Epoch 27, Batch 40, Loss 0.0003824341401923448\n",
      "Epoch 27, Batch 60, Loss 0.0008224592893384397\n",
      "Epoch 27, Batch 80, Loss 0.00034632455208338797\n",
      "Epoch 28, Batch 0, Loss 0.0003647382836788893\n",
      "Epoch 28, Batch 20, Loss 0.00034117005998268723\n",
      "Epoch 28, Batch 40, Loss 0.0003768127644434571\n",
      "Epoch 28, Batch 60, Loss 0.0005012712208554149\n",
      "Epoch 28, Batch 80, Loss 0.00034575368044897914\n",
      "Epoch 29, Batch 0, Loss 0.0006741845281794667\n",
      "Epoch 29, Batch 20, Loss 0.0002399468794465065\n",
      "Epoch 29, Batch 40, Loss 0.00027404428692534566\n",
      "Epoch 29, Batch 60, Loss 0.0002808468125294894\n",
      "Epoch 29, Batch 80, Loss 0.0002478993555996567\n",
      "Epoch 30, Batch 0, Loss 0.0006725552375428379\n",
      "Epoch 30, Batch 20, Loss 0.0003369699406903237\n",
      "Epoch 30, Batch 40, Loss 0.0005392831517383456\n",
      "Epoch 30, Batch 60, Loss 0.0002803444513119757\n",
      "Epoch 30, Batch 80, Loss 0.0002395465999143198\n",
      "Epoch 31, Batch 0, Loss 0.000404505233746022\n",
      "Epoch 31, Batch 20, Loss 0.0005657024448737502\n",
      "Epoch 31, Batch 40, Loss 0.0003453650278970599\n",
      "Epoch 31, Batch 60, Loss 0.0004317709244787693\n",
      "Epoch 31, Batch 80, Loss 0.0003073590050917119\n",
      "Epoch 32, Batch 0, Loss 0.0002666880318429321\n",
      "Epoch 32, Batch 20, Loss 0.0004101229424122721\n",
      "Epoch 32, Batch 40, Loss 0.0004453063302207738\n",
      "Epoch 32, Batch 60, Loss 0.000642507744487375\n",
      "Epoch 32, Batch 80, Loss 0.0003382949507795274\n",
      "Epoch 33, Batch 0, Loss 0.0004324456676840782\n",
      "Epoch 33, Batch 20, Loss 0.00040905625792220235\n",
      "Epoch 33, Batch 40, Loss 0.00021374256175477058\n",
      "Epoch 33, Batch 60, Loss 0.00021517513960134238\n",
      "Epoch 33, Batch 80, Loss 0.0007733080419711769\n",
      "Epoch 34, Batch 0, Loss 0.00033229964901693165\n",
      "Epoch 34, Batch 20, Loss 0.00041946585406549275\n",
      "Epoch 34, Batch 40, Loss 0.0002632163232192397\n",
      "Epoch 34, Batch 60, Loss 0.00017966389714274555\n",
      "Epoch 34, Batch 80, Loss 0.00028268585447221994\n",
      "Epoch 35, Batch 0, Loss 0.00022072732099331915\n",
      "Epoch 35, Batch 20, Loss 0.0004464010416995734\n",
      "Epoch 35, Batch 40, Loss 0.00031799430144019425\n",
      "Epoch 35, Batch 60, Loss 0.00032547174487262964\n",
      "Epoch 35, Batch 80, Loss 0.0005302214995026588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Batch 0, Loss 0.00044567036093212664\n",
      "Epoch 36, Batch 20, Loss 0.0004202554700896144\n",
      "Epoch 36, Batch 40, Loss 0.00040101970080286264\n",
      "Epoch 36, Batch 60, Loss 0.00034417095594108105\n",
      "Epoch 36, Batch 80, Loss 0.0005037141381762922\n",
      "Epoch 37, Batch 0, Loss 0.0003154866863042116\n",
      "Epoch 37, Batch 20, Loss 0.00042454441427253187\n",
      "Epoch 37, Batch 40, Loss 0.00047529165749438107\n",
      "Epoch 37, Batch 60, Loss 0.00041758466977626085\n",
      "Epoch 37, Batch 80, Loss 0.00034215234336443245\n",
      "Epoch 38, Batch 0, Loss 0.0003547605301719159\n",
      "Epoch 38, Batch 20, Loss 0.00042689728434197605\n",
      "Epoch 38, Batch 40, Loss 0.0003468747599981725\n",
      "Epoch 38, Batch 60, Loss 0.00033570267260074615\n",
      "Epoch 38, Batch 80, Loss 0.00027446908643469214\n",
      "Epoch 39, Batch 0, Loss 0.00028230255702510476\n",
      "Epoch 39, Batch 20, Loss 0.0005897572846151888\n",
      "Epoch 39, Batch 40, Loss 0.00036200491013005376\n",
      "Epoch 39, Batch 60, Loss 0.000549161050003022\n",
      "Epoch 39, Batch 80, Loss 0.0003109727695118636\n",
      "Epoch 40, Batch 0, Loss 0.0002779813075903803\n",
      "Epoch 40, Batch 20, Loss 0.00037117800093255937\n",
      "Epoch 40, Batch 40, Loss 0.00026342898490838706\n",
      "Epoch 40, Batch 60, Loss 0.0002778791240416467\n",
      "Epoch 40, Batch 80, Loss 0.00035864851088263094\n",
      "Epoch 41, Batch 0, Loss 0.0002923850843217224\n",
      "Epoch 41, Batch 20, Loss 0.0003439992724452168\n",
      "Epoch 41, Batch 40, Loss 0.0010173805058002472\n",
      "Epoch 41, Batch 60, Loss 0.0005116739775985479\n",
      "Epoch 41, Batch 80, Loss 0.00029402525979094207\n",
      "Epoch 42, Batch 0, Loss 0.00027532147942110896\n",
      "Epoch 42, Batch 20, Loss 0.00038607913302257657\n",
      "Epoch 42, Batch 40, Loss 0.0003365034353919327\n",
      "Epoch 42, Batch 60, Loss 0.00029098783852532506\n",
      "Epoch 42, Batch 80, Loss 0.000382851401809603\n",
      "Epoch 43, Batch 0, Loss 0.0002528423210605979\n",
      "Epoch 43, Batch 20, Loss 0.0002910372568294406\n",
      "Epoch 43, Batch 40, Loss 0.00033059067209251225\n",
      "Epoch 43, Batch 60, Loss 0.0003870406071655452\n",
      "Epoch 43, Batch 80, Loss 0.0004469110572244972\n",
      "Epoch 44, Batch 0, Loss 0.0003012260131072253\n",
      "Epoch 44, Batch 20, Loss 0.0002717075403779745\n",
      "Epoch 44, Batch 40, Loss 0.0002899779356084764\n",
      "Epoch 44, Batch 60, Loss 0.0002147765626432374\n",
      "Epoch 44, Batch 80, Loss 0.00041968817822635174\n",
      "Epoch 45, Batch 0, Loss 0.0010959873907268047\n",
      "Epoch 45, Batch 20, Loss 0.00030517842969857156\n",
      "Epoch 45, Batch 40, Loss 0.0003509886737447232\n",
      "Epoch 45, Batch 60, Loss 0.0007061995565891266\n",
      "Epoch 45, Batch 80, Loss 0.0005015693022869527\n",
      "Epoch 46, Batch 0, Loss 0.00024978414876386523\n",
      "Epoch 46, Batch 20, Loss 0.0002854344784282148\n",
      "Epoch 46, Batch 40, Loss 0.00035803738865070045\n",
      "Epoch 46, Batch 60, Loss 0.0002892555494327098\n",
      "Epoch 46, Batch 80, Loss 0.00028208791627548635\n",
      "Epoch 47, Batch 0, Loss 0.0004072969895787537\n",
      "Epoch 47, Batch 20, Loss 0.0002540075802244246\n",
      "Epoch 47, Batch 40, Loss 0.0003731435281224549\n",
      "Epoch 47, Batch 60, Loss 0.0003744551504496485\n",
      "Epoch 47, Batch 80, Loss 0.00029700371669605374\n",
      "Epoch 48, Batch 0, Loss 0.0004438699106685817\n",
      "Epoch 48, Batch 20, Loss 0.0003208638518117368\n",
      "Epoch 48, Batch 40, Loss 0.00022489660477731377\n",
      "Epoch 48, Batch 60, Loss 0.0004512484010774642\n",
      "Epoch 48, Batch 80, Loss 0.0011344050290063024\n",
      "Epoch 49, Batch 0, Loss 0.00030675818561576307\n",
      "Epoch 49, Batch 20, Loss 0.0003074035921599716\n",
      "Epoch 49, Batch 40, Loss 0.00030018447432667017\n",
      "Epoch 49, Batch 60, Loss 0.00036858447128906846\n",
      "Epoch 49, Batch 80, Loss 0.00036816811189055443\n"
     ]
    }
   ],
   "source": [
    "# 5. 训练模型\n",
    "def train_model(model, dataloader, epochs):\n",
    "    min_loss = float('inf')  # 初始最小损失设为正无穷大\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (seq, target) in enumerate(dataloader):\n",
    "            seq = seq.to(device).float()\n",
    "            target = target.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            seq = seq.view(-1, 7, 29)  # Reshape to (batch_size * num_stocks, time_step, input_dim)\n",
    "#             print(seq.shape)  #  [5984, 7, 30]\n",
    "            target = target.view(-1,1)  # Flatten target to have shape (batch_size * num_stocks)\n",
    "#             print(target.shape)  #  [5984, 1]\n",
    "            attention_vec, attention_probs = model(seq)\n",
    "            attention_vec = attention_vec.squeeze()  # Remove extra dimensions to match target shape\n",
    "            loss = criterion(attention_vec, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f'Epoch {epoch}, Batch {batch_idx}, Loss {loss.item()}')\n",
    "        if loss.item() < min_loss:  # 当前损失小于记录的最小损失就保存\n",
    "            min_loss = loss.item() \n",
    "            torch.save(model, './output/model/2023-11-28/sequence_encoder.pkl') \n",
    "            print('save!')\n",
    "\n",
    "# 开始训练\n",
    "train_model(sequence_encoder, dataloader, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ac046d-d766-4ec6-894b-a50a2c9103c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:36:25.186923Z",
     "iopub.status.busy": "2023-11-26T07:36:25.186487Z",
     "iopub.status.idle": "2023-11-26T07:36:25.191362Z",
     "shell.execute_reply": "2023-11-26T07:36:25.190259Z",
     "shell.execute_reply.started": "2023-11-26T07:36:25.186884Z"
    },
    "tags": []
   },
   "source": [
    "## 测试数据，加载node和edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d15b191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 480, 7, 29)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8ef1d23-380d-4812-917c-5054f0540af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:07.087217Z",
     "iopub.status.busy": "2023-11-26T07:51:07.086871Z",
     "iopub.status.idle": "2023-11-26T07:51:07.098996Z",
     "shell.execute_reply": "2023-11-26T07:51:07.098603Z",
     "shell.execute_reply.started": "2023-11-26T07:51:07.087182Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([187200, 7, 29])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.10 GiB. GPU 0 has a total capacty of 6.00 GiB of which 3.13 GiB is free. Of the allocated memory 851.01 MiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(new_week_data)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m29\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m---> 10\u001b[0m attention_vecs \u001b[38;5;241m=\u001b[39m \u001b[43msequence_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(attention_vecs\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32mD:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 27\u001b[0m, in \u001b[0;36mSequenceEncoder.forward\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,seq):\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    inp : torch.tensor (batch,time_step,input_dim)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     seq_vector,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     seq_vector \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(seq_vector)\n\u001b[0;32m     29\u001b[0m     attention_vec, attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_block(seq_vector)\n",
      "File \u001b[1;32mD:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\_Application\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:1102\u001b[0m, in \u001b[0;36mGRU.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1103\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m   1106\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.10 GiB. GPU 0 has a total capacty of 6.00 GiB of which 3.13 GiB is free. Of the allocated memory 851.01 MiB is allocated by PyTorch, and 72.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "new_week_data = test_x\n",
    "\n",
    "# 评估模型\n",
    "sequence_encoder.eval()\n",
    "\n",
    "# 不需要计算梯度\n",
    "with torch.no_grad():\n",
    "    input = torch.Tensor(new_week_data).view(-1, 7, 30).to(device)\n",
    "    print(input.size())\n",
    "    attention_vecs = sequence_encoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55d6f73c-8303-41ed-9db8-c0cd0268d7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:09.128709Z",
     "iopub.status.busy": "2023-11-26T07:51:09.128468Z",
     "iopub.status.idle": "2023-11-26T07:51:09.134282Z",
     "shell.execute_reply": "2023-11-26T07:51:09.133685Z",
     "shell.execute_reply.started": "2023-11-26T07:51:09.128687Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([374, 1, 64])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vecs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75c9d688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:10.368874Z",
     "iopub.status.busy": "2023-11-26T07:51:10.368514Z",
     "iopub.status.idle": "2023-11-26T07:51:10.376064Z",
     "shell.execute_reply": "2023-11-26T07:51:10.375616Z",
     "shell.execute_reply.started": "2023-11-26T07:51:10.368837Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   5],\n",
       "       [  0,  18],\n",
       "       ...,\n",
       "       [337, 337],\n",
       "       [337, 349],\n",
       "       [349, 349]], dtype=int32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge = np.array(np.load(\"/openbayes/input/input0/inner_edge.npy\"))\n",
    "inner_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9b44f371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:11.973509Z",
     "iopub.status.busy": "2023-11-26T07:51:11.973152Z",
     "iopub.status.idle": "2023-11-26T07:51:11.980771Z",
     "shell.execute_reply": "2023-11-26T07:51:11.980134Z",
     "shell.execute_reply.started": "2023-11-26T07:51:11.973474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 337, 337, 349],\n",
       "        [  0,   5,  18,  ..., 337, 349, 349]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge = torch.tensor(inner_edge.T, dtype=torch.int64).to(device)\n",
    "inner_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "294e50f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:13.103636Z",
     "iopub.status.busy": "2023-11-26T07:51:13.103278Z",
     "iopub.status.idle": "2023-11-26T07:51:13.110389Z",
     "shell.execute_reply": "2023-11-26T07:51:13.109332Z",
     "shell.execute_reply.started": "2023-11-26T07:51:13.103600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6346])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner_edge.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe89a3-8dbc-4e34-b9e9-2a0e6d9a18bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:37:19.380726Z",
     "iopub.status.busy": "2023-11-26T07:37:19.380348Z",
     "iopub.status.idle": "2023-11-26T07:37:19.383658Z",
     "shell.execute_reply": "2023-11-26T07:37:19.382881Z",
     "shell.execute_reply.started": "2023-11-26T07:37:19.380700Z"
    },
    "tags": []
   },
   "source": [
    "## 一周内、不同股票间的gat代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "23a3888a-5fd4-4a27-b263-12feaa43663d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:15.029186Z",
     "iopub.status.busy": "2023-11-26T07:51:15.028822Z",
     "iopub.status.idle": "2023-11-26T07:51:15.037950Z",
     "shell.execute_reply": "2023-11-26T07:51:15.037153Z",
     "shell.execute_reply.started": "2023-11-26T07:51:15.029149Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATModel(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_hidden_units, num_classes):\n",
    "        super(GATModel, self).__init__()\n",
    "        self.conv1 = GATConv(num_node_features, num_hidden_units, heads=1, dropout=0.6)\n",
    "        self.conv2 = GATConv(num_hidden_units, num_classes, heads=1, concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # 输入层\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "\n",
    "        # 输出层\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50bf56c3-eab6-402c-b2b5-e363cf767b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:15.827729Z",
     "iopub.status.busy": "2023-11-26T07:51:15.827424Z",
     "iopub.status.idle": "2023-11-26T07:51:15.838126Z",
     "shell.execute_reply": "2023-11-26T07:51:15.837459Z",
     "shell.execute_reply.started": "2023-11-26T07:51:15.827685Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([374, 64])\n",
      "torch.Size([2, 6346])\n"
     ]
    }
   ],
   "source": [
    "# node和edge\n",
    "nodes = attention_vecs.squeeze(1)  # 假设这是你的节点特征\n",
    "print(nodes.size())\n",
    "edges = inner_edge  # 假设这是你的边索引\n",
    "print(edges.size())\n",
    "\n",
    "# 创建模型\n",
    "num_node_features = 64\n",
    "num_hidden_units = 8\n",
    "num_classes = 8\n",
    "model = GATModel(num_node_features, num_hidden_units, num_classes).to(device)\n",
    "\n",
    "# 前向传播\n",
    "model.train()\n",
    "out = model(nodes, edges)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4210dd5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-26T07:51:17.346534Z",
     "iopub.status.busy": "2023-11-26T07:51:17.346158Z",
     "iopub.status.idle": "2023-11-26T07:51:17.353410Z",
     "shell.execute_reply": "2023-11-26T07:51:17.352340Z",
     "shell.execute_reply.started": "2023-11-26T07:51:17.346497Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([374, 8])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776239b8-3f91-49e2-9e8f-5551ffda956a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-py3.9",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
